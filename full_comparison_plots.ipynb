{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.util import invert\n",
    "from skimage.io import imread, imsave\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from chromemt_analysis import segment_like_paper, continuous_erosion_edt, linear_fit_to_residual_volume, parse_simulation_zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform analysis on both simulated patches and ChromEMT and compare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. load simulated data\n",
    "\n",
    "# id, zipfile, file in zipfile\n",
    "\n",
    "# basedir = Path('E:/chromemt_data/')\n",
    "# basedir = Path('/Volumes/davidh-ssd/chromemt_data/')\n",
    "basedir = Path('/Users/david/Desktop/chromemt_data/')\n",
    "\n",
    "# old, separate files\n",
    "# simulation_data = [\n",
    "#     ('sim_irregular_390', basedir / 'simulations/VoxelTest.zip', None ),\n",
    "#     ('sim_regular_390', basedir / 'simulations/VoxelTestReg.zip', None ),\n",
    "#     ('sim_inactive_cd_415', basedir / 'simulations/voxelVersion415.zip', 'voxeltestInactiveCD.dat' ),\n",
    "#     ('sim_irregular_415', basedir / 'simulations/voxelVersion415.zip', 'voxeltestIrr.dat' ),\n",
    "#     ('sim_regular_415', basedir / 'simulations/voxelVersion415.zip', 'voxeltestReg.dat' )\n",
    "# ]\n",
    "\n",
    "# new all-in-one zip\n",
    "simulation_data = [\n",
    "    ('sim_random_390', basedir / 'simulations/AllCVC.zip', 'Irr390.txt'),\n",
    "    ('sim_random_415', basedir / 'simulations/AllCVC.zip', 'Irr415.txt'),\n",
    "    ('sim_random_440', basedir / 'simulations/AllCVC.zip', 'Irr440.txt'),\n",
    "    ('sim_equidistant_320', basedir / 'simulations/AllCVC.zip', 'Reg320.txt'),\n",
    "    ('sim_equidistant_390', basedir / 'simulations/AllCVC.zip', 'Reg390.txt'),\n",
    "    ('sim_equidistant_415', basedir / 'simulations/AllCVC.zip', 'Reg415.txt'),\n",
    "    ('sim_equidistant_440', basedir / 'simulations/AllCVC.zip', 'Reg440.txt'),\n",
    "    ('sim_k562_region_cd_415', basedir / 'simulations/AllCVC.zip', 'InactiveCD.txt'),\n",
    "]\n",
    "\n",
    "# load all simulations, invert\n",
    "simulated_images = {id_: invert(parse_simulation_zip(zip_, subfile)[1].astype(np.float32)) for id_, zip_, subfile in simulation_data} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. load ChromEMT data\n",
    "\n",
    "pixel_size = 1.28\n",
    "tile_size_nm = 120.0\n",
    "tile_size = int( np.ceil( tile_size_nm / pixel_size ))\n",
    "\n",
    "patches_chromemt = {}\n",
    "\n",
    "chromemt_img = imread(basedir / '49801.tif')\n",
    "n_tiles = (1, 8, 8)\n",
    "tile_offsets = ((chromemt_img.shape[0] - tile_size) // 2 , 150, 50)\n",
    "\n",
    "cut_starts = np.meshgrid(*(np.arange(tile_offsets_i, tile_offsets_i + n_tiles_i * tile_size, tile_size ) for tile_offsets_i, n_tiles_i in zip(tile_offsets, n_tiles)), indexing='ij')\n",
    "cut_starts = np.stack(cut_starts, -1)\n",
    "cut_starts = cut_starts.reshape((np.prod(n_tiles), -1))\n",
    "\n",
    "patches_chromemt['real_chromemt_interphase'] = [chromemt_img[tuple(slice(c, c+tile_size) for c in cut_start)] for cut_start in cut_starts]\n",
    "\n",
    "chromemt_img = imread(basedir / '49803.tif')\n",
    "n_tiles = (1, 6, 6)\n",
    "tile_offsets = ((chromemt_img.shape[0] - tile_size) // 2 , 310, 130)\n",
    "\n",
    "cut_starts = np.meshgrid(*(np.arange(tile_offsets_i, tile_offsets_i + n_tiles_i * tile_size, tile_size ) for tile_offsets_i, n_tiles_i in zip(tile_offsets, n_tiles)), indexing='ij')\n",
    "cut_starts = np.stack(cut_starts, -1)\n",
    "cut_starts = cut_starts.reshape((np.prod(n_tiles), -1))\n",
    "\n",
    "patches_chromemt['real_chromemt_mitotic'] = [chromemt_img[tuple(slice(c, c+tile_size) for c in cut_start)] for cut_start in cut_starts]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) simulate experimental variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected molecules per pixel inside structure\n",
    "expected_molecules = 0.5\n",
    "\n",
    "# blur before sampling molecule pos\n",
    "sigma_diffusion = 1.0\n",
    "\n",
    "simulated_images_exp_var = {}\n",
    "\n",
    "for id_, img in simulated_images.items():\n",
    "    img = invert(img)\n",
    "    img_expected_molecules = gaussian_filter(img * expected_molecules, sigma_diffusion)\n",
    "    img_sampled_molecules = np.random.poisson(img_expected_molecules).astype(np.float32)\n",
    "    img_simulation_final = invert(img_sampled_molecules)\n",
    "    simulated_images_exp_var[id_] = img_simulation_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_central_patches(img, patch_size=94):\n",
    "\n",
    "    n_patches = [s // patch_size for s in img.shape]\n",
    "    offset = [s % patch_size // 2 for s in img.shape]\n",
    "\n",
    "    cut_starts = np.stack(np.meshgrid(*[np.arange(off, off+n*patch_size, patch_size) for off, n in zip(offset, n_patches)], indexing='ij'), -1).reshape(-1, 3)\n",
    "    cuts = [img[tuple([slice(csi, csi+patch_size) for csi in cs])] for cs in cut_starts]\n",
    "\n",
    "    return cuts\n",
    "\n",
    "simulated_patches = {id_: cut_central_patches(img) for id_, img in simulated_images.items()}\n",
    "simulated_patches_exp_var = {id_: cut_central_patches(img) for id_, img in simulated_images_exp_var.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: save volumes with experimental effects applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma zyx roughly estimated via line profiles through isolated densities in EM data\n",
    "# minimal FWHMs ~2.5px xy, ~4.5px z\n",
    "sigma = (2.0, 1.0, 1.0)\n",
    "\n",
    "# save some simulated data (with blur to mimic experimental resolution) as tiff\n",
    "for id_, img in simulated_images.items():\n",
    "    img_blurred = gaussian_filter(img, sigma)\n",
    "    imsave(basedir / f'simulations/{id_}.tif', np.expand_dims(img_blurred,1))\n",
    "\n",
    "for id_, img in simulated_images_exp_var.items():\n",
    "    img_blurred = gaussian_filter(img, sigma)\n",
    "    imsave(basedir / f'simulations/{id_}_sparse.tif', np.expand_dims(img_blurred,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma zyx roughly estimated via line profiles through isolated densities in EM data\n",
    "# minimal FWHMs ~2.5px xy, ~4.5px z\n",
    "sigma = (2.0, 1.0, 1.0)\n",
    "\n",
    "res = defaultdict(list)\n",
    "\n",
    "def get_cvc_diam(mask):\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    cvc = mask.sum() / mask.size\n",
    "        \n",
    "    erosion_radii = np.arange(0, 11)\n",
    "    trace = continuous_erosion_edt(mask)\n",
    "    est_diam, _ = linear_fit_to_residual_volume(trace, erosion_radii)\n",
    "\n",
    "    return cvc, est_diam\n",
    "\n",
    "def blur_segment_get_metrics(patch, sigma=None):\n",
    "    if sigma is not None:\n",
    "        patch = gaussian_filter(patch, sigma)\n",
    "    mask = segment_like_paper(patch)\n",
    "    return get_cvc_diam(mask)\n",
    "\n",
    "\n",
    "futures = []\n",
    "with ThreadPoolExecutor() as tpe:\n",
    "\n",
    "    # 1. submit tasks to thread pool\n",
    "    # raw simulated masks\n",
    "    for id_, patches in simulated_patches.items():\n",
    "        for patch in patches:\n",
    "            mask = invert(patch.astype(bool))        \n",
    "            futures.append(tpe.submit(get_cvc_diam, mask))\n",
    "\n",
    "    # data with blur to match microscope resolution\n",
    "    for id_, patches in simulated_patches.items():\n",
    "        for patch in patches:\n",
    "            futures.append(tpe.submit(blur_segment_get_metrics, patch, sigma))\n",
    "\n",
    "    # data with extra simulation of sparse labelling\n",
    "    for id_, patches in simulated_patches_exp_var.items():\n",
    "        for patch in patches:\n",
    "            futures.append(tpe.submit(blur_segment_get_metrics, patch, sigma))\n",
    "\n",
    "    # real data, NOTE: no extra blur is applied here\n",
    "    for id_, patches in patches_chromemt.items():\n",
    "        for patch in patches:\n",
    "            futures.append(tpe.submit(blur_segment_get_metrics, patch, None))\n",
    "\n",
    "        \n",
    "    # 2. get results, put in dict\n",
    "    # we do the same loops as above and keep iterator over common future list\n",
    "    fiter = iter(futures)\n",
    "    for id_, patches in simulated_patches.items():\n",
    "        for patch in patches:\n",
    "            cvc, est_diam = next(fiter).result()\n",
    "            \n",
    "            res['sim_type'].append('raw')\n",
    "            res['id'].append(id_)\n",
    "            res['cvc'].append(cvc)\n",
    "            res['diam'].append(est_diam)\n",
    "    print('(1/4) simulated data raw masks done.')\n",
    "    \n",
    "    for id_, patches in simulated_patches.items():\n",
    "        for patch in patches:\n",
    "            cvc, est_diam = next(fiter).result()\n",
    "            \n",
    "            res['sim_type'].append('with_blur')\n",
    "            res['id'].append(id_)\n",
    "            res['cvc'].append(cvc)\n",
    "            res['diam'].append(est_diam)\n",
    "    print('(2/4) simulated data with blur done.')\n",
    "\n",
    "    for id_, patches in simulated_patches_exp_var.items():\n",
    "        for patch in patches:\n",
    "            cvc, est_diam = next(fiter).result()\n",
    "\n",
    "            res['sim_type'].append('with_blur_sparse')\n",
    "            res['id'].append(id_)\n",
    "            res['cvc'].append(cvc)\n",
    "            res['diam'].append(est_diam)\n",
    "    print('(3/4) simulated data with blur + sparse labelling done.')\n",
    "\n",
    "    for id_, patches in patches_chromemt.items():\n",
    "        for patch in patches:\n",
    "            cvc, est_diam = next(fiter).result()\n",
    "\n",
    "            res['sim_type'].append('real_data')\n",
    "            res['id'].append(id_)\n",
    "            res['cvc'].append(cvc)\n",
    "            res['diam'].append(est_diam)\n",
    "    print('(4/4) real data done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res)\n",
    "\n",
    "df['diam'] *= 1.28\n",
    "df['cvc'] *= 100\n",
    "df['type'] = df.id.str.split('_', n=1, expand=True)[1].str.rsplit('_', n=1, expand=True)[0]\n",
    "\n",
    "# df = df[df.sim_type.isin(['with_blur_sparse','real_data'])]\n",
    "# df = df[df['type'].isin(['irregular', 'regular', 'inactive_cd'])]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(ax=ax, data=df, x='id', y='cvc', hue='sim_type')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n",
    "\n",
    "plt.rc('pdf', fonttype='42')\n",
    "plt.savefig('/Users/david/Desktop/density-figures/comparison_plot_cvc_bysimtype.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(ax=ax, data=df, x='id', y='diam', hue='sim_type')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n",
    "\n",
    "plt.rc('pdf', fonttype='42')\n",
    "plt.savefig('/Users/david/Desktop/density-figures/comparison_plot_diam_bysimtype.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res)\n",
    "\n",
    "df['diam'] *= 1.28\n",
    "df['cvc'] *= 100\n",
    "df['type'] = df.id.str.split('_', n=1, expand=True)[1].str.rsplit('_', n=1, expand=True)[0]\n",
    "\n",
    "df = df[df.sim_type.isin(['with_blur_sparse','real_data'])]\n",
    "# df = df[df['type'].isin(['irregular', 'regular', 'inactive_cd'])]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(ax=ax, data=df, x='id', y='cvc', hue='type')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n",
    "\n",
    "plt.rc('pdf', fonttype='42')\n",
    "plt.savefig('/Users/david/Desktop/density-figures/comparison_plot_cvc_onlychromemt+sparse.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(ax=ax, data=df, x='id', y='diam', hue='type')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n",
    "\n",
    "plt.rc('pdf', fonttype='42')\n",
    "plt.savefig('/Users/david/Desktop/density-figures/comparison_plot_diam_onlychromemt+sparse.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get means per id\n",
    "df.groupby('id').diam.describe()[['mean', 'std']], df.groupby('id').cvc.describe()[['mean', 'std']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('anaconda-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c56d775aced456a8ab026152645841badb60c6b5ad75d89ae0164854b3484784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
